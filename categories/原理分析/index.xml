<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>原理分析 on 记录每个瞬间</title>
    <link>https://code0xff.org/categories/%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/</link>
    <description>Recent content in 原理分析 on 记录每个瞬间</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 12 Jan 2025 01:08:07 +0800</lastBuildDate><atom:link href="https://code0xff.org/categories/%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>BTrace</title>
      <link>https://code0xff.org/post/2025/01/btrace/</link>
      <pubDate>Sun, 12 Jan 2025 01:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2025/01/btrace/</guid>
      <description>btrace的一个例子，arthas 的retransform，jdb 调试。以及其他一些分析工具，如 JDK 内置的、分布式监控工具、火焰图、jfr、visualvm、jprofiler、MAT 等等</description>
    </item>
    
    <item>
      <title>YARN原理分析</title>
      <link>https://code0xff.org/post/2025/01/yarn/</link>
      <pubDate>Sat, 11 Jan 2025 01:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2025/01/yarn/</guid>
      <description>RPC协议，客户端&amp;lt;-&amp;gt;RM，RM&amp;lt;-&amp;gt;NM，RM&amp;lt;-&amp;gt;AM，AM&amp;lt;-&amp;gt;NM，ADMIN&amp;lt;-&amp;gt;RM。使用了reactor模式，类似tomcat和jetty，也使用了异步事件处理模式。RM 内部的模块：用户交互的Web服务模块、NM管理模块、AM管理模块、application管理模块、状态机管理模块、安全管理模块、资源分配模块；其中包括ApplicationMasterService、AMLivelinessMonitor；状态机包括：RMApp 状态机、RMAppAttempt 状态机、RMContainer 状态机、RMNode 状态机。 资源调度体系：FIFO、Capacity Scheduler、Fari Scheduler；第一层，RM 中的资源调度器将资源分配给各个 AM、第二层，AM 再进一步将资源分配给它内部的各个任务；资源抢占流程、资源计算方式。层级管理方式：子队列，可以嵌套、最少容量，可以使用父队列的容量比、调度器有限选择当前资源使用率最低的、最大容量、用户权限管理。NodeManage内部模块：NodeStatusUpdater、ContainerManager、ContainerExecutor、NodeHealthCheckerService、DeletionService、Security、WebServer。分布式缓存，将应用所需的资源下载到本地再运行：public、private、application三个可见性；应用结束后会自动上传日志到HDFS，之后由JobHistory 负责清理。NM内部包括：Application 状态机、Container 状态机、LocalizedResource 状态机。container启动包括：资源本地化、启动(LinuxContainerExecutor cgroup管理)、资源清理</description>
    </item>
    
    <item>
      <title>Spark 注册数据源</title>
      <link>https://code0xff.org/post/2025/01/spark_register_source/</link>
      <pubDate>Sat, 04 Jan 2025 01:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2025/01/spark_register_source/</guid>
      <description>DataSourceRegister注册过程，自定阅读XXRelationProvider，DataSource 查找过程，DataFrameReader，DataFrameWriter，CheckpointRDDPartition，ReliableCheckpointRDD，SparkSession内部包含的变量SparkContext、sharedState、SQLContext、RuntimeConfig</description>
    </item>
    
    <item>
      <title>Spark Core相关-2</title>
      <link>https://code0xff.org/post/2025/01/spark_core_2/</link>
      <pubDate>Wed, 01 Jan 2025 01:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2025/01/spark_core_2/</guid>
      <description>调度过程，RDD的主要函数，DAGScheduler将各个RDD划分到不同stage，每个Stage包含若干个TaskSet，交给内部的并发队列处理事件；TaskScheduler有点像 YARN队列，创建调度池和本地性判断，之后交给SchedulerBackend；MemoryAllocator负责分配内存，包括off-heap和on-heap，其中的MemoryBlock包含了obj指向heap的对象、以及offset和length；TaskMemoryManager负责task的内存管理，MemoryConsumer的实现类负责消费这些内存；Task包括：ShuffleMapTask、ResultTask，TaskContext 会启动新线程运行Task；AppendOnlyMap类似HashMap但做了优化，shuffle和spill的几个类：ExternalSorter、ExternalAppendOnlyMap、ShuffleExternalSorter、UnsafeExternalSorter；ShuffleWriter和实现类体系负责写磁盘，ShuffleReader主要由ShuffleBlockFetcherIterator 去抓取数据，以及管理他们的ShuffleManager；Executor 调用 launchTask，在新线程中启动 TaskRunnerTaskRunner 又会启动 Task；Master和选举；Driver调度过程，Executor分配过程，尽可能跨Worker；集群模式下TaskSchedulerImpl-&amp;gt;StandaloneSchedulerBackend-&amp;gt;StandaloneAppClinet，跟Master通讯。Master调用launchExecutor给Wroker，Worker拼接ProcessBuilder启动新进程，CoarseGrainedExecutorBackend会跟Worker通讯。YARN cluster和client模式</description>
    </item>
    
    <item>
      <title>Llama Factory</title>
      <link>https://code0xff.org/post/2024/12/llamafactory/</link>
      <pubDate>Tue, 24 Dec 2024 22:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/12/llamafactory/</guid>
      <description>Llama Factory</description>
    </item>
    
    <item>
      <title>Spark Core相关-1</title>
      <link>https://code0xff.org/post/2024/11/spark_core/</link>
      <pubDate>Mon, 25 Nov 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/11/spark_core/</guid>
      <description>SparkContext、存储体系、RPC、Web-UI。 存储体系，BlockManager和BlockManagerMaster、MemoryManager、MemoryStore、DiskBlockManager、DiskStore。监控体系：MapOutputTracker、MapOutputTrackerMaster、MapOutputTrackerWorker。 Web-UI体系：对应的层级结构为： SparkUI -&amp;gt; WebUITab -&amp;gt; WebUIPage。执行环境：安全体系(SecurityManager、用于设置 yarn，hadoop 的 secret key)；SparkContext 会附带初始化：Metrics 体系、Listener、SparkUI、RPC 整套体系、BlockManager，storage 体系、Executor 体系、Heartbeater、KVStore、SerializerManager，还有度量类、日志体系。 PRC 体系：MessageLoop 中维护了 Inbox 的链表、每个Inbox 中为了 InboxMessage 的链表，InboxMessage包含很多实现类，如 HeartbeatReceiver ，包括了 receiveAndReply。RPC中用到了 netty的通讯体系，根据发送地址，选择对应的 Outbox，每个 Outbox维护一个 OutboxMessage的链表，再通过netty 的 NettyChannel 发送出去</description>
    </item>
    
    <item>
      <title>code-gen</title>
      <link>https://code0xff.org/post/2024/05/spark_codegen/</link>
      <pubDate>Mon, 06 May 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/05/spark_codegen/</guid>
      <description>入口点：CollapseCodegenStages，插入WholeStageCodegenExec；对于不支持的，或者 SortMergeJoinExec、ShuffledHashJoinExec 会插入 InputAdapter；代码生成可以看作是两个方向相反的递归过程：代码的整体框架由 produce/doProduce 方法负责，父节点调用子节点。代码具体处理逻辑由 consume/doConsume 方法负责，由子节点调用父节点。整个物理算子树的执行过程被InputAdapter分隔开。boradcast-hash-join跟普通的bhj类似，分割部分插入了InputAdapter。shuffle-hash-join，跟 bhj 类似，只是左右两个子节点都增加了 InputAdapter，作为code-gen 的分割。sort-merge-join 左右两边都是 InputAdapter，对code-gen做了分割，之后调用SortExec 再次增加 InputAdapter，然后是shuffle逻辑，会生成5个代码片段。BroadcastNestedLoopJoin：广播+nested loop实现。CartesianProduct 没有 code-gen</description>
    </item>
    
    <item>
      <title>Spark原理-JOIN</title>
      <link>https://code0xff.org/post/2024/05/spark_join/</link>
      <pubDate>Sat, 27 Apr 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/05/spark_join/</guid>
      <description>join的语法定义，join类型，解析、优化过程，join选择策略：hint、等值、数据size，父hash join： streamedlter 和 buildlter，数据的节点分布，对子节点的要求，JoinedRow 类型；BroadcastHashJoin 和 BroadcastExchange； ShuffleHashJoin 和 ClusteredDistribution，先将数据物化再通过AQEShuffleRead 读取； Shuffle Sort Merge Join，Sort ，Exchange，SortMergeJoinScanner(ExternalAppendOnlyUnsafeRowArray）；BroadcastNestedLoopJoinExec ，BroadcastDistribution 等价两个for循环； CartesianProduct 对子节点无要求也是两个for循环; 排序算子执行过程</description>
    </item>
    
    <item>
      <title>Spark原理-窗口函数和多维分析</title>
      <link>https://code0xff.org/post/2024/05/spark_windows_cube/</link>
      <pubDate>Sat, 27 Apr 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/05/spark_windows_cube/</guid>
      <description>cube，rollup，grouping set，窗口函数执行过程，lateral，pivot，unpivot，with cube 的代码生成</description>
    </item>
    
    <item>
      <title>Spark原理-聚合</title>
      <link>https://code0xff.org/post/2024/04/spark_agg/</link>
      <pubDate>Fri, 19 Apr 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/04/spark_agg/</guid>
      <description>聚合的基本原理，聚合方式的分类：Partial、ParitialMerge、Final、Complete；distinct 和 非 distinct聚合；DeclarativeAggregate、ImperativeAggregate，聚合迭代器；基于排序的聚合，自定义函数 V1 和 V2 实现，自定义的 classloader，V2方式的自定义聚合函数，ObjectHashAggregate，基于hash 的聚合；自定义函数下推：标量函数下推、聚合函数下推；基于Hash 的聚会</description>
    </item>
    
    <item>
      <title>Spark原理-物理计划&amp;聚合</title>
      <link>https://code0xff.org/post/2024/03/spark_plan_agg/</link>
      <pubDate>Wed, 13 Mar 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/spark_plan_agg/</guid>
      <description>Spark物理计划-聚合</description>
    </item>
    
    <item>
      <title>Spark原理-优化规则</title>
      <link>https://code0xff.org/post/2024/03/spark_optimized/</link>
      <pubDate>Mon, 04 Mar 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/spark_optimized/</guid>
      <description>子查询优化：查询合并、展开，一行一列，单行多列，多行单列，多行多列，转换为 exist，子查询上提转join，子查询重写(转为semi/anti join）；算子合并：CollapseRepartition、CollapseProject、CombineFilters、CombineUnions；常量折叠和强度消减：NullPropagation 、ConstantPropagation、OptimizeIn、ConstantFolding、ReplaceNullWithFalseInPredicate、CombineConcats；算子简化： LikeSimplification、BooleanSimplification、SimplifyBinaryComparison、PruneFilters、EliminateSerialization、SimplifyExtractValueOps； Rewrite/Replace/Eliminate规则：EliminateOuterJoin、EliminateDistinct、EliminateLimits； 下推规则：PushDownPredicates、PushPredicateThroughNonJoin、PushPredicateThroughJoin、LimitPushDown、ColumnPruning</description>
    </item>
    
    <item>
      <title>Spark原理-解析过程和Catalog</title>
      <link>https://code0xff.org/post/2024/03/spark_internal/</link>
      <pubDate>Sat, 02 Mar 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/spark_internal/</guid>
      <description>逻辑计划扩展，注入点。TreeNode的两个子类：Expression，QueryPlan。而	QueryPlan。而QueryPlan的子类是：LogicalPlan、SparkPlan。并将规则分为Batch。 CatalogV2Util#loadTable会解析：库、表、列信息，ResolveReferences。内置的一堆优化规则。查询下推、join下推。SPark的catalog体系，主要拷贝各种SupportRead、Wirte、Dialect，各种数据源的Catalog扩展如HiveCatalog。SessionCatalog 会使用hive 的meta-store走老的catalog路线。自定义函数下推，继承UnboundFunction、ScalarFunction、AggregateFunction，使用Spark的线程上下文classloader 机制加载类，也是用 新Catalog扩展如MyCatalog去执行loadFunction、functionExists</description>
    </item>
    
    <item>
      <title>LevelDB 多版本和压缩</title>
      <link>https://code0xff.org/post/2023/04/levedb-%E5%A4%9A%E7%89%88%E6%9C%AC%E5%92%8C%E5%8E%8B%E7%BC%A9/</link>
      <pubDate>Fri, 14 Apr 2023 19:20:03 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/04/levedb-%E5%A4%9A%E7%89%88%E6%9C%AC%E5%92%8C%E5%8E%8B%E7%BC%A9/</guid>
      <description>LevelDB 多版本和压缩</description>
    </item>
    
    <item>
      <title>LevelDB 辅助工具类</title>
      <link>https://code0xff.org/post/2023/04/levedb-%E5%B7%A5%E5%85%B7%E7%B1%BB/</link>
      <pubDate>Tue, 11 Apr 2023 09:20:01 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/04/levedb-%E5%B7%A5%E5%85%B7%E7%B1%BB/</guid>
      <description>LevelDB 的辅助工具类，如内存分配、编码、LRU、bloom filter等</description>
    </item>
    
    <item>
      <title>LevelDB SSTable模块</title>
      <link>https://code0xff.org/post/2023/04/levedb-sstable%E6%A8%A1%E5%9D%97/</link>
      <pubDate>Sun, 09 Apr 2023 09:22:11 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/04/levedb-sstable%E6%A8%A1%E5%9D%97/</guid>
      <description>LevelDB 的SSTable模块，存储在磁盘上的结构，包括文件格式的组织、数据文件块是如何读取的、索引文件块是如何组织的</description>
    </item>
    
    <item>
      <title>LevelDB MemTable模块</title>
      <link>https://code0xff.org/post/2023/04/levedb-memtable%E6%A8%A1%E5%9D%97/</link>
      <pubDate>Thu, 06 Apr 2023 11:32:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/04/levedb-memtable%E6%A8%A1%E5%9D%97/</guid>
      <description>LevelDB 的MemTable模块，底层使用 skip-list实现的，用来实现内存的读、写操作</description>
    </item>
    
    <item>
      <title>LevelDB Log模块</title>
      <link>https://code0xff.org/post/2023/04/levedb-log%E6%A8%A1%E5%9D%97/</link>
      <pubDate>Mon, 03 Apr 2023 11:32:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/04/levedb-log%E6%A8%A1%E5%9D%97/</guid>
      <description>LevelDB 的Log模块，用来实现WAL</description>
    </item>
    
    <item>
      <title>LevelDB 公开的接口</title>
      <link>https://code0xff.org/post/2023/03/levedb-%E5%85%AC%E5%BC%80%E6%8E%A5%E5%8F%A3/</link>
      <pubDate>Thu, 30 Mar 2023 11:32:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/03/levedb-%E5%85%AC%E5%BC%80%E6%8E%A5%E5%8F%A3/</guid>
      <description>LevelDB 的 src/include目录下的公开接口、跨平台的移植(对文件读写、线程、锁做了简单封装方便了跨平台迁移)，读写流程的大致流程等</description>
    </item>
    
    <item>
      <title>LevelDB 基本概念</title>
      <link>https://code0xff.org/post/2023/03/levedb-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link>
      <pubDate>Mon, 27 Mar 2023 11:32:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/03/levedb-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid>
      <description>LevelDB的架构，各个组件的基本原理，一些基本操作(open、增删改)，高级特性(options、自定义比较器)</description>
    </item>
    
    <item>
      <title>MySQL的并发</title>
      <link>https://code0xff.org/post/2023/01/mysql%E7%9A%84%E5%B9%B6%E5%8F%91/</link>
      <pubDate>Sun, 01 Jan 2023 08:15:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/01/mysql%E7%9A%84%E5%B9%B6%E5%8F%91/</guid>
      <description>MVCC的基本概念，读已提交、可重复读隔离级别下的ReadView，MVCC的purage；锁的基本类型，X/S/IX/IS锁；record lock、gap lock、next-key lock、insert intention lock、隐式锁；各种隔离级别下的加锁过程，SHOW ENGINE INNODB STATUS 分析加锁过程，死锁的分析</description>
    </item>
    
    <item>
      <title>MySQL的恢复</title>
      <link>https://code0xff.org/post/2022/12/mysql%E7%9A%84%E6%81%A2%E5%A4%8D/</link>
      <pubDate>Thu, 22 Dec 2022 08:15:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2022/12/mysql%E7%9A%84%E6%81%A2%E5%A4%8D/</guid>
      <description>redo log的格式(逻辑+物理混合格式)、Mini-Transaction、redo log写入过程，写入page cache，log_sys结构、redo log的文件格式，如何刷新到磁盘上的，checkpoint过程，恢复过程；   undo log的格式(逻辑格式)、undo log的组织、回滚段、系统表空间的5号page，多个回滚段、rollback的过程；以及源码中的redo log定义、undo log定义</description>
    </item>
    
    <item>
      <title>MySQL的缓存</title>
      <link>https://code0xff.org/post/2022/12/mysql%E7%9A%84%E7%BC%93%E5%AD%98/</link>
      <pubDate>Mon, 19 Dec 2022 08:15:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2022/12/mysql%E7%9A%84%E7%BC%93%E5%AD%98/</guid>
      <description>Buffer Pool、Doublewrite Buffer、Redo相关的Log Buffer，自适应Hash索引、change buffer、以及InnoDB相关的参数汇总</description>
    </item>
    
    <item>
      <title>MySQL查询分析</title>
      <link>https://code0xff.org/post/2022/12/mysql%E6%9F%A5%E8%AF%A2%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 15 Dec 2022 08:15:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2022/12/mysql%E6%9F%A5%E8%AF%A2%E5%88%86%E6%9E%90/</guid>
      <description>一些经典的RBO优化，包括子查询优化；一些CBO优化，统计信息收集，CBO的统计计算方式，常数成本调节；JOIN优化，并详细介绍了EXPLAIN的各个字段含义，其中select_type、type、Extra这几个字段比较重要，另外还有JSON个事的执行计划，optimizer trace</description>
    </item>
    
    <item>
      <title>用工具分析MySQL存储文件</title>
      <link>https://code0xff.org/post/2022/12/%E7%94%A8%E5%B7%A5%E5%85%B7%E5%88%86%E6%9E%90mysql%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6/</link>
      <pubDate>Tue, 13 Dec 2022 08:35:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2022/12/%E7%94%A8%E5%B7%A5%E5%85%B7%E5%88%86%E6%9E%90mysql%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6/</guid>
      <description>innodb_ruby是专门分析InnoDB的工具，通过这个工具能获取到系统表空间、普通表空间的统计信息，段信息、区信息，以及4个核心的SYS表；；以及索引信息统计，page信息汇总，page信息dump，还可以用图表的方式展示</description>
    </item>
    
    <item>
      <title>MySQL文件存储结构</title>
      <link>https://code0xff.org/post/2022/12/mysql%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/</link>
      <pubDate>Fri, 02 Dec 2022 08:35:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2022/12/mysql%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/</guid>
      <description>InnoDB架构包含内存、磁盘两种结构；基于磁盘的结构中包括：系统表空间、普通表空间、通用表空间、双写缓冲区、Undo表空间、redo日志；临时表空间；这里最重要的当属系统表空间 和 普通表空间；普通表空间分为段、区、页、行这些概念，256个区一组，第0组包含FSP_HDR、XDES、INODE，存储数据的地方是INDEX；系统表空间则多了Data Dictionary Header部分</description>
    </item>
    
  </channel>
</rss>
