<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>索引 on 记录每个瞬间</title>
    <link>https://code0xff.org/tags/%E7%B4%A2%E5%BC%95/</link>
    <description>Recent content in 索引 on 记录每个瞬间</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 01 Jun 2023 09:11:07 +0800</lastBuildDate><atom:link href="https://code0xff.org/tags/%E7%B4%A2%E5%BC%95/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>BitWeaving: Fast Scans for Main Memory Data Processing</title>
      <link>https://code0xff.org/post/2023/06/bitweaving/</link>
      <pubDate>Thu, 01 Jun 2023 09:11:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/06/bitweaving/</guid>
      <description>基于主内存数据库的 scan 优化，提出的技术：BitWeaving，又分为两种：BitWeaving/V 和 BitWeaving/H；BW/H 相当于是bit 级别的水平分布，将列的数据水平的分布到不同segment 中，通过亦或、以及各种位运算技术，实现了 =、!=、&amp;lt;、&amp;lt;= 的比较操作，比较完之后，每个process word 分隔符bit就会被设置为 1 或者0，然后将上下四组分别做不同的位移在 or，就能得到最终结果；BW/V 实现bit 级别的列存储，一列数据将每个数据的第一个bit存到 process word v1中，第二列存到 v2中，按照这种分布就可以实现早期裁剪，SIMD 再进一步优化，他的scan很快，但是查找需要跨多个processor word，相当于是垂直的从左往右计算，性能会 BW/H要差；而对于 VBP，其真实数据布局可以再优化，比如原先 9个processor word 一个segment，变成一个segment 3个 bit group，每个bit group 3个 processor word，这样做 cut-off的时候可以不用再加载斗鱼的processor word，节省了内存带宽，减少cache miss；从性能对比看，BW 技术在scan方面是最好的，SIMD有打包和对其开销所以效果远不如 BW，而BW 存在选择 BW/V 和 BW/H 布局的问题，也是待研究的问题</description>
    </item>
    
    <item>
      <title>Cache Conscious Indexing for Decision-Support in Main Memory</title>
      <link>https://code0xff.org/post/2023/05/cache_conscious/</link>
      <pubDate>Sun, 28 May 2023 09:11:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/05/cache_conscious/</guid>
      <description>对于主内存 OLAP 场景，提出的针对 cache有效性的优化，如果排序数组远大于 cache line，则二分查找的 cache miss 是很严重的，基本每查找一次就有一次cache miss；T树 看起来是缓存友好的，但每次查找只有 min、max做了匹配，仍然会有很大的 cache miss，B 树虽然是面向磁盘的，但有多个子节点，一次可以做多个匹配，所以cache miss 比 T 树更好一些，hash index需要占用大量空间，当然二分的好处是不用空间；在这些基础上论文提出了针对cache line的 CSS树(Cache Sensitive Search Trees)，他在排序数组基础上，增加了一个字典数组，使得整个树可以被平铺，有点像 树堆，不过它的节点有多个，个数一般跟 cache line有关，它没有子节点指针，而是用数组下标来代替，这样一个 node 内可以放更多的数据，查找起来的cache miss就会小很多；值得注意的是类似满二叉树，CSS树的字典指向的排序数组其 part-1、part-2整合跟正常排序数组是相反的；从测试结果看CSS 树的表现也不错，随着CPU和内存差距越来越大，CSS树可能会变现的更好</description>
    </item>
    
    <item>
      <title>Column Imprints: A Secondary Index Structure</title>
      <link>https://code0xff.org/post/2023/05/column_imprints/</link>
      <pubDate>Fri, 26 May 2023 18:11:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/05/column_imprints/</guid>
      <description>针对主内存数据库，提出了一种轻量级二级索引技术：imprints column，它是属于bit 向量索引家族的，zone map对于随机值正好落在min、max内的查询就无效了，仍然需要扫描，而 bit map占用的空间更大，imprint 则综合了这两者的优点，它是基于cache line做bit向量分组的，对CPU更友好，而且将一个cache line内的值统一合并为一个bit向量，占用空间更小；通过 counter 和 repeat标志位，可以实现imprint 的压缩，论文中给出了相关的压缩、查询算法，由于是针对读场景的设计，更新主要是append和索引重建；通过实验对比，imprint 对于数据分布随机和有规律的场景，表现的都很好，索引压缩效果不错，压缩后的索引占比看 imprint最少，zonemap也差不多，WAH最高；查询性能看，三个索引基本差不多，imprint略好一些，时间上imprint也略块一些，但随着选择率上升几个都趋同；总体看随选择率上升也跟scan 差不多，但是对于熵低/高的场景表现都比较稳定</description>
    </item>
    
    <item>
      <title>SQL Server Column Store Indexes</title>
      <link>https://code0xff.org/post/2023/05/sql_server_column_store_indexes/</link>
      <pubDate>Wed, 24 May 2023 18:11:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/05/sql_server_column_store_indexes/</guid>
      <description>SQL Server 11代 Denali，在行存系统上增加了列存和索引结构，这些改动并不是重新来一套，而是基于现有技术的改进，如对行做了分片segment，每个 row segment 再根据 column 进一步细分为 column segment；column segment本身是现有的 blob存储，同时还利用了压缩技术，基于 column segment 又开发出了 segment directory，这个 directory包含了一些元信息如行数量、size、多少数据被编码了、min和max等，这些改动之后，还可以跟现有的lock、log、recovery、patition、mirror、replication完全兼容整合；之后查询引擎部分也会做一些改动来兼容行、列数据，这里使用了多核、bitmap filter、算子间的内存共享、SIMD等进一步优化，根据代价模型评估，选择合适的索引，测试TPC-DS时，前面大部分数据都是批的方式处理的，而且做了并行化，只有最后的聚合、重分区是用 行模式处理的，最后效率大幅度提升</description>
    </item>
    
    <item>
      <title>Bitmap Index Design and Evaluation </title>
      <link>https://code0xff.org/post/2023/05/bitmap_index/</link>
      <pubDate>Mon, 22 May 2023 09:23:04 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/05/bitmap_index/</guid>
      <description>针对 bitmap 索引提出的一系列指导设计建议，传统方式对于带谓词的查询，一般是：全表scan、B树 索引、每个谓词做scan然后merge；使用 bitmap 后采用第三种方案效果最好，论文中提出了四种时空权衡：空间最优、时间最优、基于空间限制下的时间最优、时空权衡； 在大量数、数据基础范围较小的情况下使用 bitmap 索引效果很好，而 bitmap 可以采用 基于范围的、基于等值的；基于范围的相当于 Value-List set，在这种场景下继续拆分，如基于&amp;lt;3,3&amp;gt;的Value-List，其空间比原始的更小；论文中提出了对 Algorithm RangeEval 改进的 Algorithm RangeEval-Opt 算法，需要处理的谓词更少，只需一次扫描；论文指出 范围编码的时空权衡效果更好，之后又对比了压缩的情况，buffer的增大，对于时空权衡也有帮助</description>
    </item>
    
    <item>
      <title>Column Sketches: A Scan Accelerator for Rapid and Robust Predicate Evaluation</title>
      <link>https://code0xff.org/post/2023/05/column_sketches/</link>
      <pubDate>Wed, 17 May 2023 09:23:04 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/05/column_sketches/</guid>
      <description>B数索引 对于选择率低时效果很好、但选择率一旦上升性能就不行了；轻量级索引 Zone Map、Column Imprints、Feature Based Data Skipping对数据聚集性有要求；早期裁剪 ByteSlicing、Bit-Slicing、Approximate and Refine 在数据倾斜情况下，高位可能都是重复的效果不好。Column Sketches使用直方图统计列数据分布，同时考虑了频繁值和普通值，之后建立映射函数，将频繁值映射成唯一code，非频繁值均匀分布，通过这种映射之后，数值类型的 原先 8bit 的值，映射完只需要 2bit 就可以表示了，对于频繁唯一值也不需要回表检查进一步加速；对于分类型也是类似方式，只是不需要排序，可以直接映射。对比其他方案，Column Sketches在选择率高/低，L1 miss，tuple处理速度，数据倾斜，鲁棒性，数据加载上都很不错；Column Sketches还可以利用 SIMD加速scan，可以跟现有技术做整合</description>
    </item>
    
  </channel>
</rss>
