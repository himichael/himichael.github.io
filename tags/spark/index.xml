<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on 记录每个瞬间</title>
    <link>https://code0xff.org/tags/spark/</link>
    <description>Recent content in spark on 记录每个瞬间</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 04 Jan 2025 01:08:07 +0800</lastBuildDate><atom:link href="https://code0xff.org/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Spark 注册数据源</title>
      <link>https://code0xff.org/post/2025/01/spark_register_source/</link>
      <pubDate>Sat, 04 Jan 2025 01:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2025/01/spark_register_source/</guid>
      <description>DataSourceRegister注册过程，自定阅读XXRelationProvider，DataSource 查找过程，DataFrameReader，DataFrameWriter，CheckpointRDDPartition，ReliableCheckpointRDD，SparkSession内部包含的变量SparkContext、sharedState、SQLContext、RuntimeConfig</description>
    </item>
    
    <item>
      <title>Spark Core相关-2</title>
      <link>https://code0xff.org/post/2025/01/spark_core_2/</link>
      <pubDate>Wed, 01 Jan 2025 01:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2025/01/spark_core_2/</guid>
      <description>调度过程，RDD的主要函数，DAGScheduler将各个RDD划分到不同stage，每个Stage包含若干个TaskSet，交给内部的并发队列处理事件；TaskScheduler有点像 YARN队列，创建调度池和本地性判断，之后交给SchedulerBackend；MemoryAllocator负责分配内存，包括off-heap和on-heap，其中的MemoryBlock包含了obj指向heap的对象、以及offset和length；TaskMemoryManager负责task的内存管理，MemoryConsumer的实现类负责消费这些内存；Task包括：ShuffleMapTask、ResultTask，TaskContext 会启动新线程运行Task；AppendOnlyMap类似HashMap但做了优化，shuffle和spill的几个类：ExternalSorter、ExternalAppendOnlyMap、ShuffleExternalSorter、UnsafeExternalSorter；ShuffleWriter和实现类体系负责写磁盘，ShuffleReader主要由ShuffleBlockFetcherIterator 去抓取数据，以及管理他们的ShuffleManager；Executor 调用 launchTask，在新线程中启动 TaskRunnerTaskRunner 又会启动 Task；Master和选举；Driver调度过程，Executor分配过程，尽可能跨Worker；集群模式下TaskSchedulerImpl-&amp;gt;StandaloneSchedulerBackend-&amp;gt;StandaloneAppClinet，跟Master通讯。Master调用launchExecutor给Wroker，Worker拼接ProcessBuilder启动新进程，CoarseGrainedExecutorBackend会跟Worker通讯。YARN cluster和client模式</description>
    </item>
    
    <item>
      <title>Spark Core相关-1</title>
      <link>https://code0xff.org/post/2024/11/spark_core/</link>
      <pubDate>Mon, 25 Nov 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/11/spark_core/</guid>
      <description>SparkContext、存储体系、RPC、Web-UI。 存储体系，BlockManager和BlockManagerMaster、MemoryManager、MemoryStore、DiskBlockManager、DiskStore。监控体系：MapOutputTracker、MapOutputTrackerMaster、MapOutputTrackerWorker。 Web-UI体系：对应的层级结构为： SparkUI -&amp;gt; WebUITab -&amp;gt; WebUIPage。执行环境：安全体系(SecurityManager、用于设置 yarn，hadoop 的 secret key)；SparkContext 会附带初始化：Metrics 体系、Listener、SparkUI、RPC 整套体系、BlockManager，storage 体系、Executor 体系、Heartbeater、KVStore、SerializerManager，还有度量类、日志体系。 PRC 体系：MessageLoop 中维护了 Inbox 的链表、每个Inbox 中为了 InboxMessage 的链表，InboxMessage包含很多实现类，如 HeartbeatReceiver ，包括了 receiveAndReply。RPC中用到了 netty的通讯体系，根据发送地址，选择对应的 Outbox，每个 Outbox维护一个 OutboxMessage的链表，再通过netty 的 NettyChannel 发送出去</description>
    </item>
    
    <item>
      <title>Spark的一些优化</title>
      <link>https://code0xff.org/post/2024/10/spark_optimize/</link>
      <pubDate>Wed, 23 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/10/spark_optimize/</guid>
      <description>web-ui观察 executor指标：失败，shuffle，cache，CPU，内存，RDD数量，GC；stage关注 DAG，也是shuffle等数据，还有 Event Timeline。shuffle优化方式：增加并行度，group by变成局部聚合+全局聚合；转为 BHJ，大表 join 大表的 外表加盐，内表复制N份，再去盐gourp原始id，最后聚合；shuffle原理，HashShuffleManager(废除)，SortShuffleManager。 with 缓存优化，查询下推，自动倾斜join优化，LIMIT大数量优化，bucked join，4表join转为2个2个join增加并行度。RSS，向量化， AQE</description>
    </item>
    
    <item>
      <title>Spark-Streaming 原理</title>
      <link>https://code0xff.org/post/2024/09/spark_streaming/</link>
      <pubDate>Mon, 09 Sep 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/09/spark_streaming/</guid>
      <description>spark streaming的基本原理，包括MicroBatchExecution，ContinuousExecution，通过IncrementalExecution + 状态实现micro-batch 并复用了spark 的所有查询逻辑；Source接口支持 getOffset，commit，可以自定义各种扩展实现；Sink包括：FileStreamSink、KafkaSink、DeltaSink、、ForeachBatchSink，ForeachWriteTable；Stateful将信息存如StateStoreRDD，保存到 HDFSBackedStateStoreProvider、RocksDBStateStoreProvider 中；Stream-Stream Join使用了StreamingSymmetricHashJoin，需要保证状态；Session Window同样也是通过插入一些流相关的算子 + 状态保存实现的</description>
    </item>
    
    <item>
      <title>Spark的 数据分布</title>
      <link>https://code0xff.org/post/2024/09/data_distribution/</link>
      <pubDate>Sun, 01 Sep 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/09/data_distribution/</guid>
      <description>Distribution及相关类，Partitioning类，Partitioner类，排序的物理算子，UnsafeExternalSorter 和UnsafeInMemorySorter，spill和归并排序；shuffle操作，ShuffleDependency，ShuffleRowRDD，map端的ShuffleMapTasks，reduce端 ShuffleDependency 从shuffle manager 那里读取数据，拿到MapStauts 状态；ShuffleManager 包含了ShuffleWriter，ShuffleReader；BypassMergeSortShuffleWriter 、UnsafeShuffleWriter、SortShuffleWriter、、BlockStoreShuffleReader</description>
    </item>
    
    <item>
      <title>code-gen</title>
      <link>https://code0xff.org/post/2024/05/spark_codegen/</link>
      <pubDate>Mon, 06 May 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/05/spark_codegen/</guid>
      <description>入口点：CollapseCodegenStages，插入WholeStageCodegenExec；对于不支持的，或者 SortMergeJoinExec、ShuffledHashJoinExec 会插入 InputAdapter；代码生成可以看作是两个方向相反的递归过程：代码的整体框架由 produce/doProduce 方法负责，父节点调用子节点。代码具体处理逻辑由 consume/doConsume 方法负责，由子节点调用父节点。整个物理算子树的执行过程被InputAdapter分隔开。boradcast-hash-join跟普通的bhj类似，分割部分插入了InputAdapter。shuffle-hash-join，跟 bhj 类似，只是左右两个子节点都增加了 InputAdapter，作为code-gen 的分割。sort-merge-join 左右两边都是 InputAdapter，对code-gen做了分割，之后调用SortExec 再次增加 InputAdapter，然后是shuffle逻辑，会生成5个代码片段。BroadcastNestedLoopJoin：广播+nested loop实现。CartesianProduct 没有 code-gen</description>
    </item>
    
    <item>
      <title>Spark原理-JOIN</title>
      <link>https://code0xff.org/post/2024/05/spark_join/</link>
      <pubDate>Sat, 27 Apr 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/05/spark_join/</guid>
      <description>join的语法定义，join类型，解析、优化过程，join选择策略：hint、等值、数据size，父hash join： streamedlter 和 buildlter，数据的节点分布，对子节点的要求，JoinedRow 类型；BroadcastHashJoin 和 BroadcastExchange； ShuffleHashJoin 和 ClusteredDistribution，先将数据物化再通过AQEShuffleRead 读取； Shuffle Sort Merge Join，Sort ，Exchange，SortMergeJoinScanner(ExternalAppendOnlyUnsafeRowArray）；BroadcastNestedLoopJoinExec ，BroadcastDistribution 等价两个for循环； CartesianProduct 对子节点无要求也是两个for循环; 排序算子执行过程</description>
    </item>
    
    <item>
      <title>Spark原理-窗口函数和多维分析</title>
      <link>https://code0xff.org/post/2024/05/spark_windows_cube/</link>
      <pubDate>Sat, 27 Apr 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/05/spark_windows_cube/</guid>
      <description>cube，rollup，grouping set，窗口函数执行过程，lateral，pivot，unpivot，with cube 的代码生成</description>
    </item>
    
    <item>
      <title>Spark原理-聚合</title>
      <link>https://code0xff.org/post/2024/04/spark_agg/</link>
      <pubDate>Fri, 19 Apr 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/04/spark_agg/</guid>
      <description>聚合的基本原理，聚合方式的分类：Partial、ParitialMerge、Final、Complete；distinct 和 非 distinct聚合；DeclarativeAggregate、ImperativeAggregate，聚合迭代器；基于排序的聚合，自定义函数 V1 和 V2 实现，自定义的 classloader，V2方式的自定义聚合函数，ObjectHashAggregate，基于hash 的聚合；自定义函数下推：标量函数下推、聚合函数下推；基于Hash 的聚会</description>
    </item>
    
    <item>
      <title>Spark原理-物理计划&amp;聚合</title>
      <link>https://code0xff.org/post/2024/03/spark_plan_agg/</link>
      <pubDate>Wed, 13 Mar 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/spark_plan_agg/</guid>
      <description>Spark物理计划-聚合</description>
    </item>
    
    <item>
      <title>Spark原理-优化规则</title>
      <link>https://code0xff.org/post/2024/03/spark_optimized/</link>
      <pubDate>Mon, 04 Mar 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/spark_optimized/</guid>
      <description>子查询优化：查询合并、展开，一行一列，单行多列，多行单列，多行多列，转换为 exist，子查询上提转join，子查询重写(转为semi/anti join）；算子合并：CollapseRepartition、CollapseProject、CombineFilters、CombineUnions；常量折叠和强度消减：NullPropagation 、ConstantPropagation、OptimizeIn、ConstantFolding、ReplaceNullWithFalseInPredicate、CombineConcats；算子简化： LikeSimplification、BooleanSimplification、SimplifyBinaryComparison、PruneFilters、EliminateSerialization、SimplifyExtractValueOps； Rewrite/Replace/Eliminate规则：EliminateOuterJoin、EliminateDistinct、EliminateLimits； 下推规则：PushDownPredicates、PushPredicateThroughNonJoin、PushPredicateThroughJoin、LimitPushDown、ColumnPruning</description>
    </item>
    
    <item>
      <title>Spark原理-解析过程和Catalog</title>
      <link>https://code0xff.org/post/2024/03/spark_internal/</link>
      <pubDate>Sat, 02 Mar 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/spark_internal/</guid>
      <description>逻辑计划扩展，注入点。TreeNode的两个子类：Expression，QueryPlan。而	QueryPlan。而QueryPlan的子类是：LogicalPlan、SparkPlan。并将规则分为Batch。 CatalogV2Util#loadTable会解析：库、表、列信息，ResolveReferences。内置的一堆优化规则。查询下推、join下推。SPark的catalog体系，主要拷贝各种SupportRead、Wirte、Dialect，各种数据源的Catalog扩展如HiveCatalog。SessionCatalog 会使用hive 的meta-store走老的catalog路线。自定义函数下推，继承UnboundFunction、ScalarFunction、AggregateFunction，使用Spark的线程上下文classloader 机制加载类，也是用 新Catalog扩展如MyCatalog去执行loadFunction、functionExists</description>
    </item>
    
    <item>
      <title>Spark性能调优</title>
      <link>https://code0xff.org/post/2023/06/spark_tuning/</link>
      <pubDate>Fri, 30 Jun 2023 11:23:04 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/06/spark_tuning/</guid>
      <description>Spark性能调优</description>
    </item>
    
    <item>
      <title>Photon A Fast Query Engine for Lakehouse Systems</title>
      <link>https://code0xff.org/post/2023/01/photon-a-fast-query-engine-for-lakehouse-systems/</link>
      <pubDate>Mon, 02 Jan 2023 10:35:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2023/01/photon-a-fast-query-engine-for-lakehouse-systems/</guid>
      <description>Databricks 2022年在SIGMOD上发表的论文(最佳工业论文奖)，由于I/O方面有很多优化措施，而JVM的对向量化支持较差，之后用C++实现了向量化的执行引擎Photon，来实现进一步的性能提升；首先是从最底层scan开始替换，因为中间替换的代价较高，之后不断往上，直到某个算子Photon不能适配，则由列存转换为Spark的行存，退回到Spark执行，总体看性能可以提升好几倍</description>
    </item>
    
    <item>
      <title>Spark SQL论文</title>
      <link>https://code0xff.org/post/2022/07/spark-sql%E8%AE%BA%E6%96%87/</link>
      <pubDate>Fri, 01 Jul 2022 20:45:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2022/07/spark-sql%E8%AE%BA%E6%96%87/</guid>
      <description>Spark SQL: Relational Data Processing in Spark 论文</description>
    </item>
    
    <item>
      <title>Spark逻辑计划的解析</title>
      <link>https://code0xff.org/post/2022/03/spark%E9%80%BB%E8%BE%91%E8%AE%A1%E5%88%92%E7%9A%84%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Sun, 06 Mar 2022 11:20:43 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2022/03/spark%E9%80%BB%E8%BE%91%E8%AE%A1%E5%88%92%E7%9A%84%E8%A7%A3%E6%9E%90/</guid>
      <description>介绍spark是如何做逻辑计划解析，并优化的</description>
    </item>
    
    <item>
      <title>Spark的注入规则</title>
      <link>https://code0xff.org/post/2022/03/spark%E7%9A%84%E6%B3%A8%E5%85%A5%E8%A7%84%E5%88%99/</link>
      <pubDate>Fri, 04 Mar 2022 21:46:12 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2022/03/spark%E7%9A%84%E6%B3%A8%E5%85%A5%E8%A7%84%E5%88%99/</guid>
      <description>扩展Spark的注入规则，实现updaet</description>
    </item>
    
    <item>
      <title>Spark论文</title>
      <link>https://code0xff.org/post/2021/11/spark%E8%AE%BA%E6%96%87/</link>
      <pubDate>Sat, 06 Nov 2021 08:49:11 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2021/11/spark%E8%AE%BA%E6%96%87/</guid>
      <description>读Spark论文</description>
    </item>
    
  </channel>
</rss>
