<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2024年 on 记录每个瞬间</title>
    <link>https://code0xff.org/years/2024%E5%B9%B4/</link>
    <description>Recent content in 2024年 on 记录每个瞬间</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 24 Dec 2024 22:08:07 +0800</lastBuildDate><atom:link href="https://code0xff.org/years/2024%E5%B9%B4/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Llama Factory</title>
      <link>https://code0xff.org/post/2024/12/llamafactory/</link>
      <pubDate>Tue, 24 Dec 2024 22:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/12/llamafactory/</guid>
      <description>Llama Factory</description>
    </item>
    
    <item>
      <title>Spark Core相关-1</title>
      <link>https://code0xff.org/post/2024/11/spark_core/</link>
      <pubDate>Mon, 25 Nov 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/11/spark_core/</guid>
      <description>SparkContext、存储体系、RPC、Web-UI。 存储体系，BlockManager和BlockManagerMaster、MemoryManager、MemoryStore、DiskBlockManager、DiskStore。监控体系：MapOutputTracker、MapOutputTrackerMaster、MapOutputTrackerWorker。 Web-UI体系：对应的层级结构为： SparkUI -&amp;gt; WebUITab -&amp;gt; WebUIPage。执行环境：安全体系(SecurityManager、用于设置 yarn，hadoop 的 secret key)；SparkContext 会附带初始化：Metrics 体系、Listener、SparkUI、RPC 整套体系、BlockManager，storage 体系、Executor 体系、Heartbeater、KVStore、SerializerManager，还有度量类、日志体系。 PRC 体系：MessageLoop 中维护了 Inbox 的链表、每个Inbox 中为了 InboxMessage 的链表，InboxMessage包含很多实现类，如 HeartbeatReceiver ，包括了 receiveAndReply。RPC中用到了 netty的通讯体系，根据发送地址，选择对应的 Outbox，每个 Outbox维护一个 OutboxMessage的链表，再通过netty 的 NettyChannel 发送出去</description>
    </item>
    
    <item>
      <title>sea tunnel</title>
      <link>https://code0xff.org/post/2024/11/sae_tunnel/</link>
      <pubDate>Fri, 15 Nov 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/11/sae_tunnel/</guid>
      <description>sae tunnel</description>
    </item>
    
    <item>
      <title>k8s 网络</title>
      <link>https://code0xff.org/post/2024/11/k8s_networks/</link>
      <pubDate>Mon, 04 Nov 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/11/k8s_networks/</guid>
      <description>覆盖网络，Flannel 的 UDP模式、xvlan模式、host-gw，Calico 采用了BGP做三层转发，为防止退化为 IPIP，需要设置 BGP 的跳数。 使用 Network Policy 做网络隔离，k8s 的网络本质都是连通的，像是弱多租户。CNI 插件 的网络插件。Service 是由 kube-proxy 组件，加上 iptables 来共同实现的；所谓 Ingress，就是 Service 的“Service”。 调度：根据 etcd 的变化选择合适的 Node 做调度，Priorities为节点打分；Pod 调度失败的情况(抢占、优先级)；K8S 中两个不可替代的组件：kube-apiserver、kubelet；核心是循环控制器检查，容器运行时：CRI，除了docker还有containerd，基于虚拟化的：Kata Containers、gVisor</description>
    </item>
    
    <item>
      <title>ozone</title>
      <link>https://code0xff.org/post/2024/11/ozone/</link>
      <pubDate>Mon, 04 Nov 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/11/ozone/</guid>
      <description>ozone的三个角色Ozone Manager (OM)，Storage Container Manager (SCM)，DataNode，三个角色的具体存储内容，datanode中数据存储在 container中，按照offset保存数据的位置，recon 提供管理界面，ozone mager和 SCM 的高可用：使用 rocksdb + raft 实现的，这里用的是：ratis。整合spark，flink，presto/trino，doris 都比较容易</description>
    </item>
    
    <item>
      <title>ES的简单学习</title>
      <link>https://code0xff.org/post/2024/11/es/</link>
      <pubDate>Sun, 03 Nov 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/11/es/</guid>
      <description>主节点管理元数据，数据节点(主分片，从分片)，协调节点，预处理节点。索引-分片-segment。查询：term query、ranger、prefix、wildcard query，组合查询、聚合查询(每个分片做topN协调节点汇总topN可能数据不准确)，各种字段类型。  倒排索引原理，term-index、term dictionary、posting List。Lucene的segment包含多个document，一个document包含多个filed，每个filed有杜丽丽的索引(倒排索引)，变种的前缀树、数据编码、Roaring Bitmaps。相关性评分：TF-IDF (Term Frequency-inverse Document Frequency)、BM25 算分模型。分词器：格式处理清洗、文本切分、对切换后的单词做处理。近实时的原因：Refresh，写入的数据会定期刷盘，刷盘后生成不可变文件就可以被读取。index buffer、transaction log。分页方式：from + size、search after、scroll API、point in time。PacificA主从副本同步协议，多个master使用 raft 协议，主副本写入会带SN，将写入数据和SN一起同步给从分片。监控：cluster API，CAT api，索引生命周期管理：hot、warn、colod、delete。 索引别名、reindex、索引模版，收缩index。 ELK 架构。 ES优化：snapshoot、生命周期管理，批量读写，慢日志查询/CPU/内存/磁盘/网络 监控，索引rate，segment大小，shared数量，存储限流，refresh频率</description>
    </item>
    
    <item>
      <title>AI的简单学习</title>
      <link>https://code0xff.org/post/2025/02/ai/</link>
      <pubDate>Sat, 02 Nov 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2025/02/ai/</guid>
      <description>AI的简单学习</description>
    </item>
    
    <item>
      <title>国内几个云厂商大数据平台</title>
      <link>https://code0xff.org/post/2024/11/big_data_investigation/</link>
      <pubDate>Fri, 01 Nov 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/11/big_data_investigation/</guid>
      <description>国内几个厂商，阿里、华为、腾讯、网易的大数据平台产品粗略调研；共同点：去Ambari 自己的管控平台，报警 监控 自动化运维，智能诊断，数据治理，集成各开源组件，离线、实时、OLAP，数据服务。  阿里云：有 celeborn向量化， EMR on ECS、on ACK，Serverless， 网易：自动化诊断做的不错，Kyuubi、Impala两个增强点； 华为云：基于OpenStack还有 API，鲲鹏硬件整合、CarbonData，Superiro Scheduler；腾讯：TDBS 比较中规中矩 各种都有</description>
    </item>
    
    <item>
      <title>数据中台总结</title>
      <link>https://code0xff.org/post/2024/11/middle_platform/</link>
      <pubDate>Wed, 30 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/11/middle_platform/</guid>
      <description>数仓时代、大数据出现、大数据平台、数据中台。自顶向下建模、自底向上建模。大数据平台问题：1、指标口径不一致；2、数据重复建设；3、取数难；4、数据质量差；5、成本高；数据中台：OneData、OneService，基于大数据平台，增加数据治理能。其中元数据中心是关键(数据字典、数据血缘、数据特征)。   数据指标：口径不一致，描述错误/不清晰/难以理解/计算逻辑不清晰；面向主题域管理、原子和派生指标、规范命名。数据模型复用：DWD跨层引用，DWS/ADS/DM 汇总查询比列，接管ODS，划分主题域，构建一致性维度、事实表整合、ETL开发。数据质量：添加稽核任务、全链路监控、智能预警、质量打分、SLA。成本治理：全局资产盘点、发现问题、治理优化(无用的下线、高消耗查询、存储成本)、治理效果评估。   数据服务：提供统一接口、解决数据接入效率低、数据和接口无法复用、不知道数据被哪些应用访问；具备网关能力，全链路打通，利用中间存储加速查询，逻辑模型嵌套底层多个物理数据源。  数据安全：HDFS快照+备份；垃圾箱、权限管理：OpenLDAP + Kerberos + Ranger，两套环境物理隔离 or 复用底层设施 + 共享 meta-store。  实践： BI 赋能、打通行业的运营体系、自助取数； 研发流程：需求阶段、开发阶段、交付阶段、运维阶段。   中台建设：数据中台和业务的关系，就是鱼和水的关系，谁也离不开谁；业务想要获得更大的增长，就必须依赖数据中台，数据中台想要存活下去，就必须依赖业务的口碑和认可</description>
    </item>
    
    <item>
      <title>SRE总结</title>
      <link>https://code0xff.org/post/2024/10/sre/</link>
      <pubDate>Sat, 26 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/10/sre/</guid>
      <description>SRE是一个体系化工程，包括Pre-MTBF，MTTR(MTTI,MTTK,MTTF,MTTV)，Post-MTBF；衡量标准包括：故障时间维度，请求维度，SLI 监控的指标、SLO 指标对应的目标；包括系统层面、应用服务器层面、应用运行层面、PaaS层面、数据层面、业务层面；SLI指标方法 VALET volume、Availablity、Latency、Errors、Tickets；错误预算，燃尽图，故障定级；衡量SLO有效性三组指标：达成情况、人肉投入程度、用户满意度。落地SLO 包括确认核心交易链路、确认强弱依赖关系，核心链路要求更严格、弱依赖需要降级，核心依赖共享Error Budget，验证 核心链路 SLO包括：容量压测、混沌工程。 实践，on-call机制，也就是确认 MTTI部分；故障处理，角色分工，故障排查中定期汇报，问题扩大需要运营侧公开反馈。故障复盘：故障原因？怎样保证不出现类似问题？怎样短时间恢复业务？互联网的SRE组织架构，根据分布式架构慢慢推动演化了组织架构。以赛带练</description>
    </item>
    
    <item>
      <title>Spark的一些优化</title>
      <link>https://code0xff.org/post/2024/10/spark_optimize/</link>
      <pubDate>Wed, 23 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/10/spark_optimize/</guid>
      <description>web-ui观察 executor指标：失败，shuffle，cache，CPU，内存，RDD数量，GC；stage关注 DAG，也是shuffle等数据，还有 Event Timeline。shuffle优化方式：增加并行度，group by变成局部聚合+全局聚合；转为 BHJ，大表 join 大表的 外表加盐，内表复制N份，再去盐gourp原始id，最后聚合；shuffle原理，HashShuffleManager(废除)，SortShuffleManager。 with 缓存优化，查询下推，自动倾斜join优化，LIMIT大数量优化，bucked join，4表join转为2个2个join增加并行度。RSS，向量化， AQE</description>
    </item>
    
    <item>
      <title>DataX和Canal相关</title>
      <link>https://code0xff.org/post/2024/10/datax_canal/</link>
      <pubDate>Tue, 22 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/10/datax_canal/</guid>
      <description>DataX：读写插件，Job任务拆分，Task和Task Group，transform(filter，substr，replace，可自定义)，流控，脏数据，数据库冥等写入，ETL架构。Canal：Server（服务端-客户端模式，嵌入式模式），多个instance，包括：eventParser (数据源接入，模拟slave协议和master进行交互，协议解析)、eventSink (Parser和Store链接器，进行数据过滤，加工，分发的工作)、eventStore (数据存储)、metaManager (增量订阅&amp;amp;消费信息管理器)</description>
    </item>
    
    <item>
      <title>系统设计</title>
      <link>https://code0xff.org/post/2025/02/system_design/</link>
      <pubDate>Sun, 20 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2025/02/system_design/</guid>
      <description>系统设计</description>
    </item>
    
    <item>
      <title>微服务架构</title>
      <link>https://code0xff.org/post/2024/10/microservice_architecture/</link>
      <pubDate>Sat, 19 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/10/microservice_architecture/</guid>
      <description>五种暗能量：Simple components、Team autonomy、Fast deployment pipeline、Multiple technology stacks、Segregate by characteristics、；Service collaboration patterns：Saga 模式、CQRS 模式、；Communicate、MessagingAPI composition；一些重要的设计：、Database per Service pattern、API Gateway pattern、Circuit Breaker、Access token。可观测性模式：Log aggregation、Application metrics、Audit logging、Distributed tracing、Exception tracking、Health check API、Log deployments and changes。Testing patterns：Service Component Test、Service Integration Contract Test。UI 模式：Server-side page fragment composition、Client-side UI composition</description>
    </item>
    
    <item>
      <title>Kafka架构</title>
      <link>https://code0xff.org/post/2024/10/kafka_architecture/</link>
      <pubDate>Fri, 18 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/10/kafka_architecture/</guid>
      <description>producer, broker, consumer，consumer group消费对应的partition数据，partition 包括多个 log segment，当一个达到阈值后，变成read only，再生成一个新的；每次都是head或者tail读，以及append写，速度很快，另外用了page cache会将数据写先到缓存再刷新；每个分区都有一个leader，副本只用于备份不做读写处理；副本如果能跟上leader就会放到 ISR集合中，ISR集合中最小的读确认offset 就是高水位，低水位是下次写的offset；producer 用 ack=0、1、all来表示副本节点是否接受了消息；ZK 后面迁移到了 Z-Raft 了，还有分层存储；kafka balance 是 NP问题，kafka connect，kafka streams；未来发展：完全基于云的kafka，用C++重写的kafka，数据存储在S3上的 statefulness 的kafka</description>
    </item>
    
    <item>
      <title>scala总结</title>
      <link>https://code0xff.org/post/2024/10/scala_summary/</link>
      <pubDate>Tue, 15 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/10/scala_summary/</guid>
      <description>高阶函数、函数柯里化、隐式转换(类型，对象)，lazy延迟计算、最后一行默认返回return。内置的可变 不可变集合、自动类型推导、操作符重载、模式匹配、内部函数、对象的apply和unapply、None和Some以及Option。foldLeft ，增强的for 循环，协变、逆变，上界 和 下界</description>
    </item>
    
    <item>
      <title>大数据上云</title>
      <link>https://code0xff.org/post/2024/10/bigdata_2_cloud/</link>
      <pubDate>Thu, 03 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/10/bigdata_2_cloud/</guid>
      <description>大数据平台上云的问题：集群管控方式变了，YARN调度系统变了；安全性问题、DDos、数据治理问题；成本问题，计费策略；存储迁移，HDFS -&amp;gt; S3 语义的变化；多云高可用方案；混合云方案；适配其他业务线</description>
    </item>
    
    <item>
      <title>Parquet for Spark</title>
      <link>https://code0xff.org/post/2024/10/parquet_4_spark/</link>
      <pubDate>Wed, 02 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/10/parquet_4_spark/</guid>
      <description>Spark执行Delta的过程，通过自定义的format格式，到DataFrameWriter.saveToV1Source，在是到DeltaDataSource#createRealation，写入做优化事务处理，再用FileFormatWriter创建多个Task并行写入，之后就是到Parquet内部执行阶段。Parquet包含Row Groups，往下是Column Chunk，再往下是Page，文件尾部包含Footer和一些元数据信息。Spark是按行写入的，一次写一行，每行写对应的 column。Parquet编码包括Dictionary Encoding、Run Length Encoding (RLE)、Delta Encoding。读取的主要类是VectorizedParquetRecordReader执行一批读取，调用VectorizedColumnReaders(对应每个column)，再调用VectorizedValuesReader(读取一个column中的一段数据)，返回由上层应用消费 。</description>
    </item>
    
    <item>
      <title>一些系统设计的文章</title>
      <link>https://code0xff.org/post/2025/02/system_designing/</link>
      <pubDate>Wed, 25 Sep 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2025/02/system_designing/</guid>
      <description>国外科技巨头的系统架构</description>
    </item>
    
    <item>
      <title>Spark-Streaming 原理</title>
      <link>https://code0xff.org/post/2024/09/spark_streaming/</link>
      <pubDate>Mon, 09 Sep 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/09/spark_streaming/</guid>
      <description>spark streaming的基本原理，包括MicroBatchExecution，ContinuousExecution，通过IncrementalExecution + 状态实现micro-batch 并复用了spark 的所有查询逻辑；Source接口支持 getOffset，commit，可以自定义各种扩展实现；Sink包括：FileStreamSink、KafkaSink、DeltaSink、、ForeachBatchSink，ForeachWriteTable；Stateful将信息存如StateStoreRDD，保存到 HDFSBackedStateStoreProvider、RocksDBStateStoreProvider 中；Stream-Stream Join使用了StreamingSymmetricHashJoin，需要保证状态；Session Window同样也是通过插入一些流相关的算子 + 状态保存实现的</description>
    </item>
    
    <item>
      <title>Spark的 数据分布</title>
      <link>https://code0xff.org/post/2024/09/data_distribution/</link>
      <pubDate>Sun, 01 Sep 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/09/data_distribution/</guid>
      <description>Distribution及相关类，Partitioning类，Partitioner类，排序的物理算子，UnsafeExternalSorter 和UnsafeInMemorySorter，spill和归并排序；shuffle操作，ShuffleDependency，ShuffleRowRDD，map端的ShuffleMapTasks，reduce端 ShuffleDependency 从shuffle manager 那里读取数据，拿到MapStauts 状态；ShuffleManager 包含了ShuffleWriter，ShuffleReader；BypassMergeSortShuffleWriter 、UnsafeShuffleWriter、SortShuffleWriter、、BlockStoreShuffleReader</description>
    </item>
    
    <item>
      <title>Oracle的CDC的改动</title>
      <link>https://code0xff.org/post/2024/08/open_log_rac/</link>
      <pubDate>Sun, 25 Aug 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/08/open_log_rac/</guid>
      <description>对 CDC 工具的一些改动，支持ASM 文件读取，支持 RAC 多个活跃节点，高可用等</description>
    </item>
    
    <item>
      <title>Oracle的CDC工具编译</title>
      <link>https://code0xff.org/post/2024/07/open_log/</link>
      <pubDate>Mon, 15 Jul 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/07/open_log/</guid>
      <description>open log replicator 编译</description>
    </item>
    
    <item>
      <title>Oracle的CDC工具原理</title>
      <link>https://code0xff.org/post/2024/06/open_log_replicator/</link>
      <pubDate>Sat, 15 Jun 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/06/open_log_replicator/</guid>
      <description>open log replicator 使用</description>
    </item>
    
    <item>
      <title>英文语法的简单总结</title>
      <link>https://code0xff.org/post/2024/05/english_grammar/</link>
      <pubDate>Sun, 19 May 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/05/english_grammar/</guid>
      <description>英文语法总结</description>
    </item>
    
    <item>
      <title>code-gen</title>
      <link>https://code0xff.org/post/2024/05/spark_codegen/</link>
      <pubDate>Mon, 06 May 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/05/spark_codegen/</guid>
      <description>入口点：CollapseCodegenStages，插入WholeStageCodegenExec；对于不支持的，或者 SortMergeJoinExec、ShuffledHashJoinExec 会插入 InputAdapter；代码生成可以看作是两个方向相反的递归过程：代码的整体框架由 produce/doProduce 方法负责，父节点调用子节点。代码具体处理逻辑由 consume/doConsume 方法负责，由子节点调用父节点。整个物理算子树的执行过程被InputAdapter分隔开。boradcast-hash-join跟普通的bhj类似，分割部分插入了InputAdapter。shuffle-hash-join，跟 bhj 类似，只是左右两个子节点都增加了 InputAdapter，作为code-gen 的分割。sort-merge-join 左右两边都是 InputAdapter，对code-gen做了分割，之后调用SortExec 再次增加 InputAdapter，然后是shuffle逻辑，会生成5个代码片段。BroadcastNestedLoopJoin：广播+nested loop实现。CartesianProduct 没有 code-gen</description>
    </item>
    
    <item>
      <title>Janino简单使用</title>
      <link>https://code0xff.org/post/2024/05/janino/</link>
      <pubDate>Sun, 05 May 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/05/janino/</guid>
      <description>Janino的一些例子，Expression Evaluator，Script Evaluator，Class Body Evaluator，Simple Compiler，as a Source Code Class Loader，jsh - the Java shell，Compiler Plugin for Tomcat，code analysisi，debug</description>
    </item>
    
    <item>
      <title>Spark原理-JOIN</title>
      <link>https://code0xff.org/post/2024/05/spark_join/</link>
      <pubDate>Sat, 27 Apr 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/05/spark_join/</guid>
      <description>join的语法定义，join类型，解析、优化过程，join选择策略：hint、等值、数据size，父hash join： streamedlter 和 buildlter，数据的节点分布，对子节点的要求，JoinedRow 类型；BroadcastHashJoin 和 BroadcastExchange； ShuffleHashJoin 和 ClusteredDistribution，先将数据物化再通过AQEShuffleRead 读取； Shuffle Sort Merge Join，Sort ，Exchange，SortMergeJoinScanner(ExternalAppendOnlyUnsafeRowArray）；BroadcastNestedLoopJoinExec ，BroadcastDistribution 等价两个for循环； CartesianProduct 对子节点无要求也是两个for循环; 排序算子执行过程</description>
    </item>
    
    <item>
      <title>Spark原理-窗口函数和多维分析</title>
      <link>https://code0xff.org/post/2024/05/spark_windows_cube/</link>
      <pubDate>Sat, 27 Apr 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/05/spark_windows_cube/</guid>
      <description>cube，rollup，grouping set，窗口函数执行过程，lateral，pivot，unpivot，with cube 的代码生成</description>
    </item>
    
    <item>
      <title>Spark原理-聚合</title>
      <link>https://code0xff.org/post/2024/04/spark_agg/</link>
      <pubDate>Fri, 19 Apr 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/04/spark_agg/</guid>
      <description>聚合的基本原理，聚合方式的分类：Partial、ParitialMerge、Final、Complete；distinct 和 非 distinct聚合；DeclarativeAggregate、ImperativeAggregate，聚合迭代器；基于排序的聚合，自定义函数 V1 和 V2 实现，自定义的 classloader，V2方式的自定义聚合函数，ObjectHashAggregate，基于hash 的聚合；自定义函数下推：标量函数下推、聚合函数下推；基于Hash 的聚会</description>
    </item>
    
    <item>
      <title>Trino架构</title>
      <link>https://code0xff.org/post/2024/04/trino_architecture/</link>
      <pubDate>Sun, 07 Apr 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/04/trino_architecture/</guid>
      <description>三种角色：discovery、coordinate、worker；连接器的设计：Metadata SPI、Data Statistics SPI、Data Location SPI、Data Stream SPI；查询计划，物理计划和调度，Stage，split，page，driver；Dynamic filtering，Spill to disk，Table statistics，JOIN 策略，CBO，join order，Join pushdown</description>
    </item>
    
    <item>
      <title>简单的排列组合问题</title>
      <link>https://code0xff.org/post/2024/03/permutation/</link>
      <pubDate>Fri, 15 Mar 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/permutation/</guid>
      <description>一些概率问题</description>
    </item>
    
    <item>
      <title>Spark原理-物理计划&amp;聚合</title>
      <link>https://code0xff.org/post/2024/03/spark_plan_agg/</link>
      <pubDate>Wed, 13 Mar 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/spark_plan_agg/</guid>
      <description>Spark物理计划-聚合</description>
    </item>
    
    <item>
      <title>Spark原理-优化规则</title>
      <link>https://code0xff.org/post/2024/03/spark_optimized/</link>
      <pubDate>Mon, 04 Mar 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/spark_optimized/</guid>
      <description>子查询优化：查询合并、展开，一行一列，单行多列，多行单列，多行多列，转换为 exist，子查询上提转join，子查询重写(转为semi/anti join）；算子合并：CollapseRepartition、CollapseProject、CombineFilters、CombineUnions；常量折叠和强度消减：NullPropagation 、ConstantPropagation、OptimizeIn、ConstantFolding、ReplaceNullWithFalseInPredicate、CombineConcats；算子简化： LikeSimplification、BooleanSimplification、SimplifyBinaryComparison、PruneFilters、EliminateSerialization、SimplifyExtractValueOps； Rewrite/Replace/Eliminate规则：EliminateOuterJoin、EliminateDistinct、EliminateLimits； 下推规则：PushDownPredicates、PushPredicateThroughNonJoin、PushPredicateThroughJoin、LimitPushDown、ColumnPruning</description>
    </item>
    
    <item>
      <title>Spark原理-解析过程和Catalog</title>
      <link>https://code0xff.org/post/2024/03/spark_internal/</link>
      <pubDate>Sat, 02 Mar 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/spark_internal/</guid>
      <description>逻辑计划扩展，注入点。TreeNode的两个子类：Expression，QueryPlan。而	QueryPlan。而QueryPlan的子类是：LogicalPlan、SparkPlan。并将规则分为Batch。 CatalogV2Util#loadTable会解析：库、表、列信息，ResolveReferences。内置的一堆优化规则。查询下推、join下推。SPark的catalog体系，主要拷贝各种SupportRead、Wirte、Dialect，各种数据源的Catalog扩展如HiveCatalog。SessionCatalog 会使用hive 的meta-store走老的catalog路线。自定义函数下推，继承UnboundFunction、ScalarFunction、AggregateFunction，使用Spark的线程上下文classloader 机制加载类，也是用 新Catalog扩展如MyCatalog去执行loadFunction、functionExists</description>
    </item>
    
    <item>
      <title>Compaction in Apache Iceberg</title>
      <link>https://code0xff.org/post/2024/03/compaction-_in_apache_iceberg/</link>
      <pubDate>Thu, 29 Feb 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/compaction-_in_apache_iceberg/</guid>
      <description>压缩，可以将多个小文件合并为大文件提高读性能，几种压缩策略：binpack（简单合并）、sort、z-order（适合多列查询），Expire Snapshots 可以删除过期的数据文件，还提供了参数可以自动删除manifest 文件、保留多少manifest文件，以及清除orphan 文件</description>
    </item>
    
    <item>
      <title>Copy-On-Write vs Merge-On-Read in Apache Iceberg</title>
      <link>https://code0xff.org/post/2024/03/cow_mor_iceberg/</link>
      <pubDate>Wed, 28 Feb 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/cow_mor_iceberg/</guid>
      <description>Copy-On-Write适用的场景和优缺点，Merge-On-Read的 position deletes、equality deletes 原理，以及适用的场景，优缺点，如何选择COW和MOR，以及如何配置他们</description>
    </item>
    
    <item>
      <title>The Life of a Read/Write Query for Apache Iceberg Tables</title>
      <link>https://code0xff.org/post/2024/03/the_life_of_iceberg/</link>
      <pubDate>Mon, 26 Feb 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/the_life_of_iceberg/</guid>
      <description>介绍了存储的结构，元数据层包括：manifest files、manifest list, metadata files，catalog指向最新的 metadata files；每一层都可以做裁减，包括数据层，介绍了读取、time travel过程，是自上往下的读取和裁减过程；写入过程：插入、删除、merge过程，写 过程是自下而上的，通过 切换catalog指向，利用OCC控制并发，实现ACID</description>
    </item>
    
    <item>
      <title>Iceberg 简单总结</title>
      <link>https://code0xff.org/post/2024/02/icer_berg/</link>
      <pubDate>Sun, 25 Feb 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/02/icer_berg/</guid>
      <description>branch 和 tag，schema、partition、sort order演化，快照的维护（合并，删除孤儿文件等），manifest list 和 manifest files 两级布局；Hive的问题以及iceberg的优化：list是O(1)的，细粒度的partition，OCC，并发冲突，单节点的plan；Hidden partitioning，Time travelVersion rollback。支持：Spark、Flink、Hive、Trino、ClickHouse、Presto、Dremio、starrocks、Athena、EMR、Impala、Dori</description>
    </item>
    
    <item>
      <title>Data Ingestion: Tool Selection Strategy</title>
      <link>https://code0xff.org/post/2024/02/data_ingestion_tool-selection-strategy/</link>
      <pubDate>Mon, 19 Feb 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/02/data_ingestion_tool-selection-strategy/</guid>
      <description>1、工具选择标准：策略标准、定价标准、数据功能、数据源/目标、数据契约； 工具偏好：批加载、CDC、连接器、基于代码； 3、摄取工具选择策略</description>
    </item>
    
    <item>
      <title>YARN 简单总结</title>
      <link>https://code0xff.org/post/2024/03/yarn_summary/</link>
      <pubDate>Sun, 11 Feb 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/03/yarn_summary/</guid>
      <description>YARN 的简单使用总结</description>
    </item>
    
    <item>
      <title>Data engineering at Meta</title>
      <link>https://code0xff.org/post/2024/02/data-engineering-at-meta/</link>
      <pubDate>Fri, 02 Feb 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/02/data-engineering-at-meta/</guid>
      <description>High-Level Overview of the internal tech stack</description>
    </item>
    
    <item>
      <title>Data Ingestion: Architectural Patterns</title>
      <link>https://code0xff.org/post/2024/01/data_ingestion_architectural_patterns/</link>
      <pubDate>Mon, 15 Jan 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/01/data_ingestion_architectural_patterns/</guid>
      <description>data ingestion 的几种架构：Unified Data Repository、Data Virtualization、ETL、ELT、Stream Processing</description>
    </item>
    
    <item>
      <title>Hive MetaStore的实现和优化</title>
      <link>https://code0xff.org/post/2024/01/hms/</link>
      <pubDate>Sun, 14 Jan 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/01/hms/</guid>
      <description>Hive MetaStore的实现原理，Hive Thrift 客户端和服务端的实现，MetaCat对 HMS 的兼容以及优化，Spark调用 HMS 的逻辑</description>
    </item>
    
    <item>
      <title>Analyzing and Comparing Lakehouse Storage Systems</title>
      <link>https://code0xff.org/post/2024/01/lakehouse_storage_systems/</link>
      <pubDate>Wed, 10 Jan 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/01/lakehouse_storage_systems/</guid>
      <description>讨论了 LakeHouse 系统设计的难点，在不可变高延迟的对象存储之上，增加事务特性，三大系统都使用了OCC做隔离，事务实现都用了MVCC，源数据库管理delta和hudi用了表格式，iceberg用了层次存储(单节点处理)，数据更新三者都支持CoW(适合读多写少场景)，hudi和iceberg支持MoR(适合写多的场景)</description>
    </item>
    
    <item>
      <title>系统调优</title>
      <link>https://code0xff.org/post/2024/01/system_tuning/</link>
      <pubDate>Sun, 07 Jan 2024 08:35:19 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/01/system_tuning/</guid>
      <description>一些系统调优的排查工具汇总</description>
    </item>
    
    <item>
      <title>Doris Advanced</title>
      <link>https://code0xff.org/post/2024/01/doris_advanced/</link>
      <pubDate>Fri, 05 Jan 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/01/doris_advanced/</guid>
      <description>Pipeline Execution Engine, Nereids-the Brand New Planner, High-Concurrency Point Query, Materialized View, Statistics, Join Optimization.  Multi-catalog, Spark Doris Connector, Other Connector, Plugin Development Manual, CloudCanal Data Import, DBT Doris Adapter, UDF, cluster management, Data Admin, Other Manager, Maintenance and Monitor, Metadata Operations and Maintenance</description>
    </item>
    
    <item>
      <title>Doris Basic</title>
      <link>https://code0xff.org/post/2024/01/doris/</link>
      <pubDate>Fri, 05 Jan 2024 09:08:07 +0800</pubDate>
      
      <guid>https://code0xff.org/post/2024/01/doris/</guid>
      <description>Introduce Doris,include: Data Model(Aggregate Model,Unique Model,Duplicate Model), Data Partition(Rollup),Index(Inverted Index,BloomFilter Index,NGram BloomFilter Index,Bitmap Index). Import Scenes,Import Way(Broker Load,Routine Load,Spark Load,Stream Load,MySql Load,S3 Load,Insert Into,Importing Data in JSON Format,Min Load Replica Num),Export,Update and Delete</description>
    </item>
    
  </channel>
</rss>
